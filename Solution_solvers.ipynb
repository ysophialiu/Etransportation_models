{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains all the solution solvers:\n",
    "\n",
    "* Bayesian optimization\n",
    "\n",
    "* Random embedding Bayesian optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions used\n",
    "\n",
    "\n",
    "### Normalization ( scale variable from [min, max] to [0,1] ):\n",
    "a = (b-min)/(max-min) \n",
    "\n",
    "### de-normalization ( scale from [0,1] to [min, max] ):\n",
    "b = a*(max-min) + min\n",
    "\n",
    "### scale variable:\n",
    "scale $a\\in [a_l,a_u]$ to $b\\in [b_l,b_u]$\n",
    "\n",
    "$b = \\frac{a-a_l}{(a_u-a_l)}(b_u-b_l)+b_l$\n",
    "\n",
    "### standardization (scale to be normally distributed N(0,1) ):\n",
    "x with $\\mu, \\sigma$\n",
    "\n",
    "$y\\sim N(0.1)$, $y = \\frac{x-\\mu}{\\sigma}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate y, with 0\n",
    "def gen_high_dimension_variable(nn): ## nn: number of random y, nn<=10, need to adjust 100 to big value\n",
    "    rand_yy = []\n",
    "    rand_yy.append([0] * dim)# add 0 list\n",
    "    #rand_yy.append([int(i/2) for i in x_real_u_bound.tolist()])\n",
    "    for i in range (nn - 1): #(nn-1):\n",
    "        test_y = np.random.uniform(x_real_l_bound.tolist(), x_real_u_bound.tolist()).astype(int) #np.random.randint(0,x_real_u_bound.tolist()) #torch.FloatTensor(low_dim).uniform_(y_l_bound, y_u_bound).to(ddtype)\n",
    "        rand_yy.append(test_y)\n",
    "    return torch.FloatTensor(rand_yy).to(ddtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define collect initial points\n",
    "\n",
    "def generate_initial_data_BO(n):  # n is number of initial value want to generate\n",
    "    train_x = gen_high_dimension_variable(n)\n",
    "    exact_obj = Optimization_function(train_x).unsqueeze(-1).to(ddtype)\n",
    "    best_observation_value = exact_obj.max().item()\n",
    "    best_observation_x = train_x[exact_obj.argmax().item()]\n",
    "\n",
    "    return train_x,exact_obj, best_observation_value,  best_observation_x #train_x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP, ModelListGP,FixedNoiseGP\n",
    "from botorch import fit_gpytorch_model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "from botorch.acquisition.analytic import ExpectedImprovement,UpperConfidenceBound,ProbabilityOfImprovement, PosteriorMean\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_cyclic\n",
    "from botorch.optim.fit import fit_gpytorch_torch\n",
    "from botorch.utils.transforms import normalize, unnormalize, standardize\n",
    "\n",
    "\n",
    "# one step of iteration (GP and acquisition), and find the next point\n",
    "\n",
    "def get_next_points_BO(init_x, init_y, best_init_y, bounds_init_x, BATCH_SIZE):\n",
    "    \n",
    "    #global feed\n",
    "\n",
    "    BO_bound = (torch.tensor([[0],[1]])).repeat(1,dim).to(ddtype)\n",
    "    \n",
    "    norm_init_x = normalize(init_x, bounds=bounds_init_x) # normalize x into [0,1]\n",
    "    \n",
    "    mean_init_y = init_y.mean().item() # mean of y\n",
    "    std_init_y = init_y.std().item()  # std of y\n",
    "    \n",
    "    norm_init_y = (init_y-mean_init_y)/std_init_y  # standardize y    \n",
    "    norm_init_Y_var = torch.full_like(norm_init_y, y_variance) # y with noise    \n",
    "    norm_best_init_y = norm_init_y.max().item() # best stardized y\n",
    "    #print(norm_init_x,norm_init_y,norm_init_Y_var)\n",
    "    \n",
    "    single_model = FixedNoiseGP(norm_init_x,norm_init_y,norm_init_Y_var) # define GP: single task homoskedastic exact GP\n",
    "   \n",
    "    mml = ExactMarginalLogLikelihood(single_model.likelihood,single_model) # define likelihood to fit GP:The exact marginal log likelihood (MLL) for an exact Gaussian process with a Gaussian likelihood.\n",
    "\n",
    "    fit_gpytorch_model(mml) # Fit hyperparameters of a GPyTorch model, L-BFGS-B via scipy.optimize.minimize().\n",
    "    #fit_gpytorch_model(mml, optimizer=fit_gpytorch_torch) # Fit hyperparameters of a GPyTorch model, line search\n",
    "\n",
    "    EI = ExpectedImprovement(model = single_model,best_f = norm_best_init_y) # define acquisition function by GP\n",
    "\n",
    "    #EI = UpperConfidenceBound(model = single_model) # define acquisition function by GP\n",
    "\n",
    "\n",
    "    #print('1')\n",
    "    norm_candidates, _ = optimize_acqf(\n",
    "                    acq_function = EI,\n",
    "                    bounds = BO_bound,\n",
    "                    q = BATCH_SIZE,\n",
    "                    num_restarts = 50,\n",
    "                    raw_samples = 1000)\n",
    "        \n",
    "    candidates = unnormalize(norm_candidates, bounds=bounds_init_x)\n",
    "\n",
    "    return candidates.int().to(ddtype)#, norm_candidates   # round to the lowest closet integer; change type back to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "\n",
    "# define run BO\n",
    "def BO_run(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_):\n",
    "    \n",
    "    warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "    verbose = False\n",
    "\n",
    "    best_observed_all = []\n",
    "\n",
    "    best_observed_all_x = []\n",
    "\n",
    "\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "\n",
    "        print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "        best_observed = []\n",
    "        best_observed_x = []\n",
    "\n",
    "\n",
    "        # generate initial training data and initialize model\n",
    "        init_x, init_y, best_init_y, best_init_x = generate_initial_data_BO(N_initial)\n",
    "        #best_observed_high = low_to_high_dimension(A,best_init_x)\n",
    "\n",
    "        best_observed.append(best_init_y)\n",
    "        best_observed_x.append(best_init_x)\n",
    "\n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "            new_candidates = get_next_points_BO(init_x, init_y, best_init_y, x_real_bound, BATCH_SIZE)\n",
    "\n",
    "            new_results = Optimization_function(new_candidates).unsqueeze(-1)\n",
    "\n",
    "            init_x = torch.cat([init_x,new_candidates])\n",
    "            init_y = torch.cat([init_y,new_results])\n",
    "\n",
    "            best_init_y = init_y.max().item()\n",
    "            best_init_x = init_x[init_y.argmax().item()]\n",
    "\n",
    "            #print(new_results)\n",
    "\n",
    "            best_observed.append(best_init_y)\n",
    "            best_observed_x.append(best_init_x)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                        f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "                        f\"({max(best_random):>4.2f}), \"\n",
    "                        f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\".\", end=\"\")                    \n",
    "\n",
    "        best_observed_all.append(best_observed)\n",
    "        best_observed_all_x.append(best_observed_x)\n",
    "\n",
    "    return best_observed_all,best_observed_all_x, init_x, init_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### add more trial\n",
    "\n",
    "# define BO add batch size (Follow up previous, run more iterations)\n",
    "    \n",
    "# run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "\n",
    "def BO_add_iter(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_,best_observed_all_,best_observed_all_x_, init_x_, init_y_,x_real_bound_):\n",
    "    verbose = False\n",
    "\n",
    "    best_init_y_ = init_y_.max().item()\n",
    "    \n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        new_candidates = get_next_points_BO(init_x_, init_y_, best_init_y_, x_real_bound_, BATCH_SIZE_)\n",
    "        new_results = daily_revenue_BOTorch(new_candidates).unsqueeze(-1)\n",
    "\n",
    "        init_x_ = torch.cat([init_x_,new_candidates])\n",
    "        init_y_ = torch.cat([init_y_,new_results])\n",
    "\n",
    "        best_init_y = init_y_.max().item()\n",
    "        best_init_x = init_x_[init_y_.argmax().item()]\n",
    "\n",
    "        #print(new_results)\n",
    "\n",
    "        best_observed_all_[0].append(best_init_y)\n",
    "        best_observed_all_x_[0].append(best_init_x)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "                    f\"({max(best_random):>4.2f}), \"\n",
    "                    f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "                )\n",
    "        else:\n",
    "            print(\".\", end=\"\")                   \n",
    "            \n",
    "    return best_observed_all_,best_observed_all_x_, init_x_, init_y_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###### add more trial\n",
    "\n",
    "# define BO add batch size (Follow up previous, run more iterations)\n",
    "    \n",
    "# run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "\n",
    "def BO_add_iter(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_,best_observed_,best_observed_x_,init_x_, init_y_, best_init_y_, x_real_bound_):\n",
    "    \n",
    "    #global feed\n",
    "   \n",
    "    best_init_y_ = best_observed_all[0]\n",
    "    best_observed_all\n",
    "    \n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        new_candidates = get_next_points_BO(init_x_, init_y_, best_init_y_, x_real_bound_, BATCH_SIZE_)\n",
    "        new_results = daily_revenue_BOTorch(new_candidates).unsqueeze(-1)\n",
    "\n",
    "        init_x_ = torch.cat([init_x_,new_candidates])\n",
    "        init_y_ = torch.cat([init_y_,new_results])\n",
    "\n",
    "        best_init_y = init_y_.max().item()\n",
    "        best_init_x = init_x_[init_y_.argmax().item()]\n",
    "\n",
    "        #print(new_results)\n",
    "\n",
    "        best_observed_.append(best_init_y)\n",
    "        best_observed_x_.append(best_init_x)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "                    f\"({max(best_random):>4.2f}), \"\n",
    "                    f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "                )\n",
    "        else:\n",
    "            print(\".\", end=\"\")                   \n",
    "            \n",
    "    return best_observed_,best_observed_x_, init_x_, init_y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Embedding Bayesian Optimization REMBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the projection matrix A as a (d x D) tensor\n",
    "def gen_projection_rembo(d: int, D: int) -> torch.Tensor: #d low dimension, D high dimension\n",
    "    AA = torch.randn( D,d, dtype=ddtype)\n",
    "    return AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate y in low dimension, with 0\n",
    "def gen_low_dimension_variable(nn): ## nn: number of random y, nn<=10, need to adjust 100 to big value\n",
    "    rand_yy = []\n",
    "    rand_yy.append([0] * low_dim)# add 0 list\n",
    "    for i in range (nn-1):#(nn):\n",
    "        test_y = np.random.uniform(y_l_bound, y_u_bound,low_dim)#torch.FloatTensor(low_dim).uniform_(y_l_bound, y_u_bound).to(ddtype)\n",
    "        rand_yy.append(test_y)\n",
    "    return torch.FloatTensor(rand_yy).to(ddtype)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generate y in low dimension, with 0\n",
    "def gen_low_dimension_variable(nn): ## nn: number of random y, nn<=10, need to adjust 100 to big value\n",
    "    rand_yy = []\n",
    "    rand_yy.append([0] * low_dim)# add 0 list\n",
    "    for i in range (nn-1):\n",
    "        test_y = np.random.uniform(y_l_bound, y_u_bound,low_dim)#torch.FloatTensor(low_dim).uniform_(y_l_bound, y_u_bound).to(ddtype)\n",
    "        rand_yy.append(test_y)\n",
    "    return torch.FloatTensor(rand_yy).to(ddtype)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# convert low dimension y to high dimension x\n",
    "def low_to_high_dimension(AA,yy): \n",
    "#yy is the low dimension variable, in how_dim\n",
    "#AA is random embedding matrix, low_dim * dim\n",
    "    scale_xx = torch.t(torch.matmul(AA,torch.t(yy)))\n",
    "    print(scale_xx[1][0:10].tolist())\n",
    "    # project to box bound of scale_x\n",
    "    scale_xx = torch.clamp(scale_xx, min=x_l_bound, max=x_u_bound)\n",
    "    print(scale_xx[1][0:10].tolist())\n",
    "    scale_xx_ = (scale_xx-x_l_bound)/(x_u_bound-x_l_bound)\n",
    "    print(scale_xx_[1][0:10].tolist())\n",
    "    real_xx = scale_xx_*x_real_u_bound\n",
    "    print(real_xx[1][0:10].int().to(ddtype))\n",
    "    return real_xx.int().to(ddtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert low dimension y to high dimension x\n",
    "def low_to_high_dimension(AA,yy): \n",
    "#yy is the low dimension variable, in how_dim\n",
    "#AA is random embedding matrix, low_dim * dim\n",
    "    scale_xx = torch.t(torch.matmul(AA,torch.t(yy)))\n",
    "    # project to box bound of scale_x\n",
    "    scale_xx = torch.clamp(scale_xx, min=x_l_bound, max=x_u_bound)\n",
    "    scale_xx_ = (scale_xx-x_l_bound)/(x_u_bound-x_l_bound)\n",
    "    #print(scale_xx_)\n",
    "    real_xx = scale_xx_*(x_real_u_bound - x_real_l_bound) + x_real_l_bound #scale_xx_*x_real_u_bound\n",
    "    #print(real_xx)\n",
    "    return real_xx.int().to(ddtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define collect initial points\n",
    "\n",
    "def generate_initial_data_REMBO(AA,n):  # n is number of initial value want to generate\n",
    "    gen_low = gen_low_dimension_variable(n)\n",
    "    train_x = low_to_high_dimension(AA,gen_low)\n",
    "    exact_obj = Optimization_function(train_x).unsqueeze(-1).to(ddtype)\n",
    "    best_observation_value = exact_obj.max().item()\n",
    "    best_observation_low = gen_low[exact_obj.argmax().item()]\n",
    "\n",
    "    return gen_low,exact_obj, best_observation_value,  best_observation_low #train_x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP, ModelListGP,FixedNoiseGP\n",
    "from botorch import fit_gpytorch_model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "from botorch.acquisition.analytic import ExpectedImprovement,UpperConfidenceBound,ProbabilityOfImprovement\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_cyclic\n",
    "from botorch.optim.fit import fit_gpytorch_torch\n",
    "from botorch.utils.transforms import normalize, unnormalize, standardize\n",
    "\n",
    "\n",
    "# one step of iteration (GP and acquisition), and find the next point\n",
    "\n",
    "def get_next_points_REMBO(init_x, init_y, best_init_y, bounds_init_x, BATCH_SIZE):\n",
    "\n",
    "    BO_bound = (torch.tensor([[0],[1]])).repeat(1,low_dim).to(ddtype)\n",
    "    \n",
    "    norm_init_x = normalize(init_x, bounds=bounds_init_x) # normalize x into [0,1]\n",
    "    \n",
    "    mean_init_y = init_y.mean().item() # mean of y\n",
    "    std_init_y = init_y.std().item()  # std of y\n",
    "    \n",
    "    norm_init_y = (init_y-mean_init_y)/std_init_y  # standardize y    \n",
    "    norm_init_Y_var = torch.full_like(norm_init_y, y_variance) # y with noise    \n",
    "    norm_best_init_y = norm_init_y.max().item() # best stardized y\n",
    "    #print(norm_init_x,norm_init_y,norm_init_Y_var)\n",
    "    \n",
    "    single_model = FixedNoiseGP(norm_init_x,norm_init_y,norm_init_Y_var) # define GP: single task homoskedastic exact GP\n",
    "   \n",
    "    mml = ExactMarginalLogLikelihood(single_model.likelihood,single_model) # define likelihood to fit GP:The exact marginal log likelihood (MLL) for an exact Gaussian process with a Gaussian likelihood.\n",
    "\n",
    "    fit_gpytorch_model(mml) # Fit hyperparameters of a GPyTorch model, L-BFGS-B via scipy.optimize.minimize().\n",
    "    #fit_gpytorch_model(mml, optimizer=fit_gpytorch_torch) # Fit hyperparameters of a GPyTorch model, line search\n",
    "\n",
    "    EI = ExpectedImprovement(model = single_model,best_f = norm_best_init_y) # define acquisition function by GP\n",
    "\n",
    "    #EI = UpperConfidenceBound(model = single_model) # define acquisition function by GP\n",
    "\n",
    "\n",
    "    #print('1')\n",
    "    norm_candidates, _ = optimize_acqf(\n",
    "                    acq_function = EI,\n",
    "                    bounds = BO_bound,\n",
    "                    q = BATCH_SIZE,\n",
    "                    num_restarts = 50,\n",
    "                    raw_samples = 1000)\n",
    "        \n",
    "    candidates = unnormalize(norm_candidates, bounds=bounds_init_x)\n",
    "\n",
    "    return candidates.to(ddtype)#, norm_candidates   # round to the lowest closet integer; change type back to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "import pickle\n",
    "\n",
    "\n",
    "# define run rembo\n",
    "def REMBO_run(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_):\n",
    "\n",
    "    warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "    verbose = False\n",
    "\n",
    "    best_observed_all = []\n",
    "\n",
    "    best_observed_all_x = []\n",
    "\n",
    "    A_all = []\n",
    "    \n",
    "    intermid = []\n",
    "\n",
    "\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "        A = gen_projection_rembo(low_dim,dim)\n",
    "\n",
    "        A_all.append(A)\n",
    "\n",
    "\n",
    "        print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "        best_observed = []\n",
    "        best_observed_x = []\n",
    "\n",
    "\n",
    "        # generate initial training data and initialize model\n",
    "        init_x, init_y, best_init_y, best_init_x = generate_initial_data_REMBO(A,N_initial)\n",
    "        #best_observed_high = low_to_high_dimension(A,best_init_x)\n",
    "\n",
    "        best_observed.append(best_init_y)\n",
    "        best_observed_x.append(best_init_x)\n",
    "\n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "            new_candidates = get_next_points_REMBO(init_x, init_y, best_init_y, y_bound, BATCH_SIZE)\n",
    "\n",
    "            new_high = low_to_high_dimension(A,new_candidates)\n",
    "\n",
    "            new_results = Optimization_function(new_high).unsqueeze(-1)\n",
    "\n",
    "            init_x = torch.cat([init_x,new_candidates])\n",
    "            init_y = torch.cat([init_y,new_results])\n",
    "\n",
    "            best_init_y = init_y.max().item()\n",
    "            best_init_x = init_x[init_y.argmax().item()]\n",
    "\n",
    "            #print(new_results)\n",
    "\n",
    "            best_observed.append(best_init_y)\n",
    "            best_observed_x.append(best_init_x)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                        f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "                        f\"({max(best_random):>4.2f}), \"\n",
    "                        f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\".\", end=\"\")                    \n",
    "\n",
    "        best_observed_all.append(best_observed)\n",
    "        best_observed_all_x.append(best_observed_x)\n",
    "        \n",
    "        # save intermediate files\n",
    "        pickle.dump([best_observed_all,best_observed_all_x, init_x, init_y, A_all], open( 'result/intermid.p', \"wb\" ) )\n",
    "\n",
    "    return best_observed_all,best_observed_all_x, init_x, init_y, A_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP, ModelListGP,FixedNoiseGP\n",
    "from botorch import fit_gpytorch_model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "from botorch.acquisition.analytic import ExpectedImprovement,UpperConfidenceBound,ProbabilityOfImprovement\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_cyclic\n",
    "from botorch.optim.fit import fit_gpytorch_torch\n",
    "from botorch.utils.transforms import normalize, unnormalize, standardize\n",
    "\n",
    "\n",
    "# one step of iteration (GP and acquisition), and find the next point\n",
    "\n",
    "def get_next_points_REMBO_ac(init_x, init_y, best_init_y, bounds_init_x, BATCH_SIZE,ac_function):\n",
    "\n",
    "    BO_bound = (torch.tensor([[0],[1]])).repeat(1,low_dim).to(ddtype)\n",
    "    \n",
    "    norm_init_x = normalize(init_x, bounds=bounds_init_x) # normalize x into [0,1]\n",
    "    \n",
    "    mean_init_y = init_y.mean().item() # mean of y\n",
    "    std_init_y = init_y.std().item()  # std of y\n",
    "    \n",
    "    norm_init_y = (init_y-mean_init_y)/std_init_y  # standardize y    \n",
    "    norm_init_Y_var = torch.full_like(norm_init_y, y_variance) # y with noise    \n",
    "    norm_best_init_y = norm_init_y.max().item() # best stardized y\n",
    "    #print(norm_init_x,norm_init_y,norm_init_Y_var)\n",
    "    \n",
    "    single_model = FixedNoiseGP(norm_init_x,norm_init_y,norm_init_Y_var) # define GP: single task homoskedastic exact GP\n",
    "   \n",
    "    mml = ExactMarginalLogLikelihood(single_model.likelihood,single_model) # define likelihood to fit GP:The exact marginal log likelihood (MLL) for an exact Gaussian process with a Gaussian likelihood.\n",
    "\n",
    "    fit_gpytorch_model(mml) # Fit hyperparameters of a GPyTorch model, L-BFGS-B via scipy.optimize.minimize().\n",
    "    #fit_gpytorch_model(mml, optimizer=fit_gpytorch_torch) # Fit hyperparameters of a GPyTorch model, line search\n",
    "\n",
    "    ###### define different acquisition functions\n",
    "    #EI = ExpectedImprovement(model = single_model,best_f = norm_best_init_y) # define acquisition function by GP\n",
    "    if ac_function == 'EI':\n",
    "        EI = ExpectedImprovement(model = single_model,best_f = norm_best_init_y) # define acquisition function by GP\n",
    "    elif ac_function == 'PI':\n",
    "        EI = ProbabilityOfImprovement(model = single_model,best_f = norm_best_init_y)\n",
    "    elif ac_function == 'UCB':\n",
    "        EI = UpperConfidenceBound(model = single_model, beta = 0.2) # define acquisition function by GP\n",
    "    elif ac_function == 'PM':\n",
    "        EI = PosteriorMean(model= single_model)\n",
    "\n",
    "\n",
    "\n",
    "    #print('1')\n",
    "    norm_candidates, _ = optimize_acqf(\n",
    "                    acq_function = EI,\n",
    "                    bounds = BO_bound,\n",
    "                    q = BATCH_SIZE,\n",
    "                    num_restarts = 50,\n",
    "                    raw_samples = 1000)\n",
    "        \n",
    "    candidates = unnormalize(norm_candidates, bounds=bounds_init_x)\n",
    "\n",
    "    return candidates.to(ddtype)#, norm_candidates   # round to the lowest closet integer; change type back to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "import pickle\n",
    "\n",
    "\n",
    "# define run rembo\n",
    "def REMBO_run_ac(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_,ac_function):\n",
    "    global A_0, init_x_0, init_y_0, best_init_y_0, best_init_x_0 \n",
    "    #print(A, init_x, init_y, best_init_y, best_init_x)\n",
    "    warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "    verbose = False\n",
    "\n",
    "    best_observed_all = []\n",
    "\n",
    "    best_observed_all_x = []\n",
    "\n",
    "    A_all = []\n",
    "    \n",
    "    intermid = []\n",
    "\n",
    "\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "        #A = gen_projection_rembo(low_dim,dim)\n",
    "\n",
    "        A_all.append(A_0)\n",
    "\n",
    "\n",
    "        print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "        best_observed = []\n",
    "        best_observed_x = []\n",
    "\n",
    "\n",
    "        # generate initial training data and initialize model\n",
    "        init_x, init_y, best_init_y, best_init_x = init_x_0, init_y_0, best_init_y_0, best_init_x_0\n",
    "        #best_observed_high = low_to_high_dimension(A,best_init_x)\n",
    "\n",
    "        best_observed.append(best_init_y)\n",
    "        best_observed_x.append(best_init_x)\n",
    "\n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "            new_candidates = get_next_points_REMBO_ac(init_x, init_y, best_init_y, y_bound, BATCH_SIZE,ac_function)\n",
    "\n",
    "            new_high = low_to_high_dimension(A_0,new_candidates)\n",
    "\n",
    "            new_results = Optimization_function(new_high).unsqueeze(-1)\n",
    "\n",
    "            init_x = torch.cat([init_x,new_candidates])\n",
    "            init_y = torch.cat([init_y,new_results])\n",
    "\n",
    "            best_init_y = init_y.max().item()\n",
    "            best_init_x = init_x[init_y.argmax().item()]\n",
    "\n",
    "            #print(new_results)\n",
    "\n",
    "            best_observed.append(best_init_y)\n",
    "            best_observed_x.append(best_init_x)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                        f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "                        f\"({max(best_random):>4.2f}), \"\n",
    "                        f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\".\", end=\"\")                    \n",
    "\n",
    "        best_observed_all.append(best_observed)\n",
    "        best_observed_all_x.append(best_observed_x)\n",
    "        \n",
    "        # save intermediate files\n",
    "        pickle.dump([best_observed_all,best_observed_all_x, init_x, init_y, A_all], open( 'result/intermid.p', \"wb\" ) )\n",
    "\n",
    "    return best_observed_all,best_observed_all_x, init_x, init_y, A_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### add more trial\n",
    "\n",
    "def REMBO_add_trail(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_):\n",
    "\n",
    "\n",
    "    warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "    verbose = False\n",
    "\n",
    "\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "        A = gen_projection_rembo(low_dim,dim)\n",
    "\n",
    "        A_all.append(A)\n",
    "\n",
    "\n",
    "        print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "        best_observed = []\n",
    "        best_observed_x = []\n",
    "\n",
    "\n",
    "        # generate initial training data and initialize model\n",
    "        init_x, init_y, best_init_y, best_init_x = generate_initial_data_REMBO(A,N_initial)\n",
    "        #best_observed_high = low_to_high_dimension(A,best_init_x)\n",
    "\n",
    "        best_observed.append(best_init_y)\n",
    "        best_observed_x.append(best_init_x)\n",
    "\n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "            new_candidates = get_next_points_REMBO(init_x, init_y, best_init_y, y_bound, BATCH_SIZE)\n",
    "\n",
    "            new_high = low_to_high_dimension(A,new_candidates)\n",
    "\n",
    "            new_results = Optimization_function(new_high).unsqueeze(-1)\n",
    "\n",
    "            init_x = torch.cat([init_x,new_candidates])\n",
    "            init_y = torch.cat([init_y,new_results])\n",
    "\n",
    "            best_init_y = init_y.max().item()\n",
    "            best_init_x = init_x[init_y.argmax().item()]\n",
    "\n",
    "            #print(new_results)\n",
    "\n",
    "            best_observed.append(best_init_y)\n",
    "            best_observed_x.append(best_init_x)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                        f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "                        f\"({max(best_random):>4.2f}), \"\n",
    "                        f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\".\", end=\"\")                    \n",
    "\n",
    "        best_observed_all.append(best_observed)\n",
    "        best_observed_all_x.append(best_observed_x)\n",
    "    \n",
    "    return best_observed_all,best_observed_all_x, init_x, init_y, A_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generate y, with 0\n",
    "def gen_high_dimension_variable(nn): ## nn: number of random y, nn<=10, need to adjust 100 to big value\n",
    "    rand_yy = []\n",
    "    rand_yy.append([0] * dim)# add 0 list\n",
    "\n",
    "    for i in range (nn-1):\n",
    "        test_y = np.random.uniform(x_real_l_bound.tolist(), x_real_u_bound.tolist()).astype(int) #np.random.randint(0,x_real_u_bound.tolist()) #torch.FloatTensor(low_dim).uniform_(y_l_bound, y_u_bound).to(ddtype)\n",
    "        rand_yy.append(test_y)\n",
    "    return torch.FloatTensor(rand_yy).to(ddtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define collect initial points\n",
    "\n",
    "def generate_initial_data_BO(n):  # n is number of initial value want to generate\n",
    "    train_x = gen_high_dimension_variable(n)\n",
    "    exact_obj = Optimization_function(train_x).unsqueeze(-1).to(ddtype)\n",
    "    best_observation_value = exact_obj.max().item()\n",
    "    best_observation_x = train_x[exact_obj.argmax().item()]\n",
    "\n",
    "    return train_x,exact_obj, best_observation_value,  best_observation_x #train_x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define run BO\n",
    "def Random_search(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_):\n",
    "       \n",
    "    best_observed_all = []\n",
    "\n",
    "    best_observed_all_x = []\n",
    "\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "        print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "        best_observed = []\n",
    "        best_observed_x = []\n",
    "\n",
    "        rand_x = [np.random.uniform(x_real_l_bound.tolist(), x_real_u_bound.tolist()).astype(int)]\n",
    "        init_x = torch.FloatTensor(rand_x).to(ddtype)\n",
    "        \n",
    "        init_y = Optimization_function(init_x).unsqueeze(-1).to(ddtype)\n",
    "        \n",
    "        best_init_y = init_y.max().item()\n",
    "        \n",
    "        best_init_x = init_x[init_y.argmax().item()]\n",
    "        \n",
    "        best_observed.append(best_init_y)\n",
    "        best_observed_x.append(best_init_x)\n",
    "\n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, N_BATCH + 1):    \n",
    "            \n",
    "            rand_x_new = [np.random.uniform(x_real_l_bound.tolist(), x_real_u_bound.tolist()).astype(int)]\n",
    "            init_x_new = torch.FloatTensor(rand_x_new).to(ddtype)\n",
    "        \n",
    "            init_y_new = Optimization_function(init_x_new).unsqueeze(-1).to(ddtype)\n",
    "\n",
    "    \n",
    "            init_x = torch.cat([init_x,init_x_new])\n",
    "            init_y = torch.cat([init_y,init_y_new])\n",
    "\n",
    "            best_init_y = init_y.max().item()\n",
    "            best_init_x = init_x[init_y.argmax().item()]\n",
    "\n",
    "            #print(new_results)\n",
    "\n",
    "            best_observed.append(best_init_y)\n",
    "            best_observed_x.append(best_init_x)\n",
    "\n",
    "            print(\".\", end=\"\")                    \n",
    "\n",
    "        best_observed_all.append(best_observed)\n",
    "        best_observed_all_x.append(best_observed_x)\n",
    "\n",
    "    return best_observed_all,best_observed_all_x, init_x, init_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add iteration\n",
    "def Random_add_iter(N_initial_,BATCH_SIZE_,N_BATCH_,N_TRIALS_,Run_result_):\n",
    "       \n",
    "    best_observed_all = Run_result[0]\n",
    "    best_observed_all_x = Run_result[1]\n",
    "    #init_x = Run_result[2]\n",
    "    #init_y = Run_result[3]\n",
    "\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "        print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "        best_observed = best_observed_all[trial - 1]\n",
    "        best_observed_x = best_observed_all_x [trial - 1]\n",
    "\n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, N_BATCH + 1):    \n",
    "            \n",
    "            rand_x_new = [np.random.uniform(x_real_l_bound.tolist(), x_real_u_bound.tolist()).astype(int)]\n",
    "            \n",
    "            init_x_new = torch.FloatTensor(rand_x_new).to(ddtype)\n",
    "            #print(rand_x_new)\n",
    "            init_y_new = Optimization_function(init_x_new).unsqueeze(-1).to(ddtype)\n",
    "            #print(init_y_new)\n",
    "    \n",
    "            if init_y_new >= best_observed[-1]:\n",
    "                best_observed.append(init_y_new)\n",
    "                best_observed_x.append(init_x_new)\n",
    "            else:\n",
    "                best_observed.append(best_observed[-1])\n",
    "                best_observed_x.append(best_observed_x[-1])\n",
    "          \n",
    "\n",
    "            print(\".\", end=\"\")                    \n",
    "\n",
    "    return best_observed_all,best_observed_all_x, init_x, init_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
